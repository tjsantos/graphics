<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Ray Tracer</title>
  <link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
  <link rel="stylesheet" href="../modern-normalize.css">
  <link rel="stylesheet" href="../style.css">
</head>

<body>
<main class="container">
<header class="text-center ungutter">
  <h1>Ray Tracer</h1>
  <img
    src="./images/ray-tracer-bunny-logo.jpg"
    alt="Ray traced bunny in Cornell box with direct illumination progressive global illumination"
  >
</header>
<h2 class="text-center">Overview</h2>
<p>
  This project implements a physically-based renderer using the well-known technique
  of ray tracing. More specifically, it uses path tracing to implement global illumination
  for more realistic lighting in 3D renderings. Furthermore, this ray tracer is optimized for
  speed and quality by using a Bounding Volume Hierarchy (BVH) as an acceleration structure and
  by using adaptive sampling as a noise reduction technique. Overall, it can produce quality
  renderings of 3D scenes in reasonable amounts of time. Some sample renderings are presented below,
  as well as explanations of the techniques and optimizations to make it all work.
</p>

<h2 class="text-center">Part 1: Ray Generation and Intersection</h2>
<p>
  Ray tracing works by emulating the way light travels in the real world--as photons originating
  from light sources and bouncing off various objects until it reaches your eyes. In practice,
  this is done in reverse, tracing the path light takes by starting from the eyes and looking
  in some direction at some object that reflects light from a light source. Thus, the ray
  tracer starts from a given camera position and view direction, generates appropriate viewing
  rays for each pixel in the image, and figure's out the pixel's color based on the object
  that the ray hit and its position/orientation relative to the scene's lighting.
</p>
<p>
  Let us first approach the ray generation. We start with an image that we want to create
  in screen space coordinates, i.e. 800 x 600 pixels from a particular viewpoint. Samples are
  generated for each pixel by generating rays from the camera to the image view plane pixel and
  transforming to world coordinates, giving us a parametric equation for the ray,
  <code>r(t) = o + td</code>,
  where <code>o</code> is where the ray originates, <code>d</code> is the direction the ray
  travels, and <code>t</code> is a parameter that varies to make <code>r(t)</code> represent
  any position on the ray.
</p>
<p>
  Next, we want to figure out which object the ray hits. We'll explore intersections with two
  types of geometries: triangles and spheres.
</p>
<p>
  We can figure out if the ray hits a triangle by calculating the barycentric coordinates of
  the intersection point with the plane containing the triangle. This can be done with the
  equation <code>o + td = (1 - u - v)p1 + u*p2 + v*p3</code>, where <code>p1, p2</code> and
  <code>p3</code> are the triangle points and <code>u, v, (1 - u - v)</code> are barycentric
  coordinates. This equation can be rearranged to find the unknown values (t, u, v)
  for the intersection:
</p>
<pre>
  td + u(p1 - p2) + v(p1 - p3) = p1 - o,
</pre>
<p>
  or in matrix-vector form,
</p>
<pre>
  [d, (p1 - p2), (p1 - p3)] * [t; u; v] = [p1 - o].
</pre>
<p>
  This can be solved with basic linear algebra techniques, but a particularly efficient approach
  is to use the
  <a href="https://en.wikipedia.org/wiki/M%C3%B6ller%E2%80%93Trumbore_intersection_algorithm" target="_blank">
    Möller–Trumbore intersection algorithm</a>.
  We can verify that the equation is solvable and has a valid <code>t > 0</code> and
  valid barycentric coordinates <code>u >= 0, v >= 0, (1 - u - v) >= 0</code> that land inside
  the triangle to determine triangle intersection.
</p>
<p>
  To determine intersection with spheres, we substitute the ray position into the sphere equation
  and solve for <code>t</code>.
</p>
<pre>
  |(o + td - c)|^2 - R^2 = 0
</pre>
<p>
  Here, <code>c</code> is the sphere center, <code>R</code> is the sphere radius, and
  <code>o + td</code> is a point on the sphere when the equation holds. Expanding this
  out, we get a quadratic equation for <code>t</code> (the "." here means dot product).
</p>
<pre>
  (d . d)t^2 + (2(o - c) . d)t + ((o - c) . (o - c) - R^2) = 0
</pre>
<p>
  If we can solve for a valid <code>t > 0</code>, we have ray intersection with the sphere.
</p>
<p>
  With the object intersection information, we can do a lighting and color calculation for the
  pixels to accurately represent what our eyes should see. For now, we can color based off the
  surface normals at the intersection to observe that our implementation of ray generation
  and object intersection works as expected.
</p>
<div class="image-grid-3 text-center">
  <div>
    <figure>
      <img src="./images/p1-CBspheres.png" alt="Ray traced spheres in a Cornell box.">
      <figcaption>
      </figcaption>
    </figure>
  </div>
  <div>
    <figure>
      <img src="./images/p1-cow.png" alt="Ray traced spheres in a Cornell box.">
      <figcaption>
      </figcaption>
    </figure>
  </div>
  <div>
    <figure>
      <img src="./images/p1-teapot.png" alt="Ray traced spheres in a Cornell box.">
      <figcaption>
      </figcaption>
    </figure>
  </div>
</div>

<h2 class="text-center">Part 2: Bounding Volume Hierarchy</h2>

<h2 class="text-center">Part 3: Direct Illumination</h2>

<h2 class="text-center">Part 4: Global Illumination</h2>

<h2 class="text-center">Part 5: Adaptive Sampling</h2>


</main>

</body>
</html>
